{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "acf80ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\") or getpass(\"Enter API key:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f28cecbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"openai/gpt-oss-20b\", model_provider=\"groq\", temperature=0.0)\n",
    "creative_llm = init_chat_model(\"openai/gpt-oss-20b\", model_provider=\"groq\", temperature=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08cec009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! üåç How can I assist you today?', additional_kwargs={'reasoning_content': 'The user says \"Hello WOrld\". Probably just greeting. We can respond. Should correct \"WOrld\" maybe. Let\\'s respond with a friendly greeting.'}, response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 75, 'total_tokens': 129, 'completion_time': 0.047985075, 'prompt_time': 0.004854198, 'queue_time': 0.046518431, 'total_time': 0.052839273}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_4c4aa6a4a4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--b458cf93-4f00-4117-9493-5f7f9fd2676d-0', usage_metadata={'input_tokens': 75, 'output_tokens': 54, 'total_tokens': 129})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creative_llm.invoke(\"Hello WOrld\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65485db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"\"\"\n",
    "If there is no enemy within, the enemy outside can do us no harm.‚Äù1\n",
    "\n",
    "Ever since a Hezbollah suicide bomber in 1983 blew up a truck packed with explosives and killed 241 Marines in Beirut, combating Islamic terrorist organizations has been a priority for U.S. intelligence, security, and law enforcement agencies. However, for those of us who have followed the spiraling growth of Islamic terrorism in the 1980s and 1990s, it seemed as if the U.S was sluggishly reactive. They made little headway in extensive counterterrorism programs designed at penetrating and dismantling Islamic terror groups.2\n",
    "\n",
    "How was it possible for the hijackers and their plot to remain off the radar of intelligence and law enforcement?\n",
    "The 9/11 attack put a spotlight on the failures of the security agencies tasked to protect the U.S. against acts of terror. How was it possible for 19 hijackers and their ambitious plot to remain off the radar of intelligence and law enforcement? The truth, as I discovered during 18 months of reporting for my book, Why America Slept: The Failure to Prevent 9/11, was not that the plot had gone undetected, but rather that the agencies responsible for monitoring and fighting terrorism had failed to share information, something that would have made it possible to connect the dots before the attack occurred.\n",
    "\n",
    "The failures were more substantive than mere interagency rivalries between the CIA, FBI, NSA, and local law enforcement. Exclusive interviews I had with top intelligence officers and FBI officials revealed that the origins and depth of the dysfunction inside America‚Äôs counterintelligence programs was an internecine bureaucratic war that left little room for working together. Sharing information was given lip service but seldom practiced, particularly when the intelligence at stake was judged as having ‚Äúhigh value.‚Äù\n",
    "\n",
    "If the CIA had alerted the State Department, the two Saudis would have been on a watch list that barred them from entering the United States.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "857b0b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "system_prompt = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are an AI assistant and your name is {name} that helps generate article titles\",\n",
    "    input_variables=[\"name\"]\n",
    ")\n",
    "\n",
    "user_prompt = HumanMessagePromptTemplate.from_template(\n",
    "    \"\"\"You are tasked with creating a name for a article. The article is here for you to examine:\n",
    "\n",
    "    ---\n",
    "\n",
    "    {article}\n",
    "\n",
    "    ---\n",
    "\n",
    "    The name should be based of the conext of the article. Be creative, but make sure the names are clear, catchy,\n",
    "    and relavant to the theme of the article.\n",
    "\n",
    "    Only output the article name, no other explaination or\n",
    "    text   can be provided. \"\"\",\n",
    "    input_variables=[\"article\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa04b81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are tasked with creating a name for a article. The article is here for you to examine:\\n\\n    ---\\n\\n    TEST STRING\\n\\n    ---\\n\\n    The name should be based of the conext of the article. Be creative, but make sure the names are clear, catchy,\\n    and relavant to the theme of the article.\\n\\n    Only output the article name, no other explaination or\\n    text   can be provided. '"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt.format(name=\"joe\",article=\"TEST STRING\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9df6ef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "first_prompt = ChatPromptTemplate.from_messages([system_prompt, user_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec83aef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'System: You are an AI assistant and your name is joe that helps generate article titles\\nHuman: You are tasked with creating a name for a article. The article is here for you to examine:\\n\\n    ---\\n\\n    TEST_STRING\\n\\n    ---\\n\\n    The name should be based of the conext of the article. Be creative, but make sure the names are clear, catchy,\\n    and relavant to the theme of the article.\\n\\n    Only output the article name, no other explaination or\\n    text   can be provided. '"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_prompt.format(name=\"joe\",article=\"TEST_STRING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82b5742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_one = (\n",
    "    {\"article\": lambda x: x[\"article\"], \n",
    "     \"name\": lambda x:x[\"name\"]}\n",
    "    | first_prompt\n",
    "    | creative_llm\n",
    "    | {\"article_title\": lambda x: x.content}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0eddfc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_title_msg= chain_one.invoke({\n",
    "    \"article\": article,\n",
    "    \"name\": \"Joe\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a95e7d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article_title': 'The Silent War Within: How U.S. Intelligence Silos Allowed 9/11'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_title_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "08bd945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are an AI assistant that helps build good articles\"\n",
    ")\n",
    "\n",
    "second_user_prompt = HumanMessagePromptTemplate.from_template(\n",
    "    \"\"\"You are tasked with creating a descripion for the\n",
    "      article. The article is here for you to examine:\n",
    "\n",
    "    ---\n",
    "\n",
    "    {article}\n",
    "\n",
    "    ---\n",
    "\n",
    "    Here is the article title: {article_title}\n",
    "\n",
    "    Ouput SEO friendly article description. Do not output anything other than description.\n",
    "\n",
    "\"\"\",\n",
    "    input_variables=[\"article\", \"article_title\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "98286fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt= ChatPromptTemplate([system_prompt, second_user_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc5c5666",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_two = (\n",
    "    {\"article\": lambda x:x[\"article\"],\n",
    "     \"article_title\": lambda x:x[\"article_title\"]}\n",
    "    | second_prompt\n",
    "    | llm\n",
    "    | {\"Summary\": lambda x:x.content}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a440b4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "description_msg = chain_two.invoke(\n",
    "    {\"article\" : article,\n",
    "     \"article_title\" :      article_title_msg[\"article_title\"]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "04aebb28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Summary': 'Explore how U.S. intelligence silos and interagency rivalry let 9/11 terrorists slip through the cracks, revealing a failure of information sharing and counterterrorism.'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8c9e27a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"\n",
    "Hi, I am Harmesh. I am currently pursuing my B.Tech in Computer Science at Lovely Professional University. I specialize in Data Science and Machine Learning.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "509cddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "third_system_prompt = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are an AI assistant that helps to review and rewrite given paragraph\"\n",
    ")\n",
    "\n",
    "third_user_prompt = HumanMessagePromptTemplate.from_template(\n",
    "    \"\"\"You are tasked with reviewing the paragraph \n",
    "       and rewrite it with proper grammar and wrting. The paragraph is here for you to examine:\n",
    "\n",
    "    ---\n",
    "\n",
    "    {paragraph}\n",
    "\n",
    "    ---\n",
    "\n",
    "    Choose one paragraph to review and edit. During your edit ensure you provide\n",
    "    constructive feedback to the user so they can learn where to improve their own writing.,\n",
    "\n",
    "\n",
    "\"\"\",\n",
    "    input_variables=[\"paragraph\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3c86f4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "third_prompt = ChatPromptTemplate([third_system_prompt, third_user_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2e80f85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml/Documents/RAG-Experiments/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:2324: PydanticJsonSchemaWarning: Default value (FieldInfo(annotation=NoneType, required=True, json_schema_extra={'descripion': 'The original Paragraph'}),) is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
      "/home/ml/Documents/RAG-Experiments/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:2324: PydanticJsonSchemaWarning: Default value (FieldInfo(annotation=NoneType, required=True, description='The improved edited Paragraph'),) is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Paragraph(BaseModel):\n",
    "    original_paragraph: str = Field(descripion = \"The original Paragraph\"),\n",
    "    edited_paragraph: str = Field(description=\"The improved edited Paragraph\"),\n",
    "    feedback: int = Field(description=\"Constructive feedback about the original paragrpah out of 100\")\n",
    "\n",
    "structured_llm = creative_llm.with_structured_output(Paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8a6a1db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_three= (\n",
    "    {\"paragraph\": lambda x:x[\"paragraph\"]}\n",
    "    | third_prompt\n",
    "    | structured_llm\n",
    "    | {\"output\": lambda x:x.edited_paragraph}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "23fd7379",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_msg = chain_three.invoke({\"paragraph\":paragraph})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dc26c677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': 'Hello, I‚Äôm Harmesh. I am currently pursuing a B.Tech in Computer Science at Lovely Professional University, where I specialize in Data Science and Machine Learning.'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ef09b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "image_prompt = PromptTemplate(\n",
    "    input_variables=[\"article\"],\n",
    "    template=\"\"\"\n",
    "    Generate a prompt with less than 500 characters to generate an image\n",
    "    based on the following article ; {article}\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc023801",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG-Experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
